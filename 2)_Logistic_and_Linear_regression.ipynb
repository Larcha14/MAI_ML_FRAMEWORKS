{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ToGqcEm3li11"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#–†–µ–≥—Ä–µ—Å—Å–∏—è"
      ],
      "metadata": {
        "id": "1GxlRWaB1iY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "nXVcrKi31pOd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiFZlYa6lNeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f405a9a5-9819-4664-ad70-37d3149fe66c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple regression dataset shape: (39574, 6)\n",
            "   Invoice  CustomerID  TotalCheck  TotalQuantity  NumLines  MeanPrice\n",
            "0   489434     13085.0      505.30            166         8   4.081250\n",
            "1   489435     13085.0      145.80             60         4   2.625000\n",
            "2   489436     13078.0      630.33            193        19   3.730526\n",
            "3   489437     15362.0      310.75            145        23   3.628261\n",
            "4   489438     18102.0     2286.24            826        17   2.591176\n",
            "\n",
            "Feature matrix shape: (39574, 3)\n",
            "Target vector shape: (39574,)\n",
            "\n",
            "Train size: 31659\n",
            "Test size: 7915\n",
            "\n",
            "=== Baseline Linear Regression (simple features, no scaling) ===\n",
            "MAE:  215.55\n",
            "RMSE: 605.22\n",
            "R¬≤:   0.6301\n",
            "\n",
            "Coefficients (feature -> weight):\n",
            "TotalQuantity: 0.7245\n",
            "NumLines: 6.6625\n",
            "MeanPrice: 7.5319\n",
            "Intercept: 93.43906975346869\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/–£—á–µ–±–∞/–§—Ä–µ–∏ÃÜ–º–≤–æ—Ä–∫–∏/data\")\n",
        "SIMPLE_REG_PATH = DATA_DIR / \"regression_data_simple.csv\"\n",
        "\n",
        "reg_simple = pd.read_csv(SIMPLE_REG_PATH)\n",
        "\n",
        "print(\"Simple regression dataset shape:\", reg_simple.shape)\n",
        "print(reg_simple.head())\n",
        "\n",
        "feature_cols = [\"TotalQuantity\", \"NumLines\", \"MeanPrice\"]\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "X = reg_simple[feature_cols].values\n",
        "y = reg_simple[target_col].values\n",
        "\n",
        "print(\"\\nFeature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lin_reg.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Baseline Linear Regression (simple features, no scaling) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n",
        "\n",
        "print(\"\\nCoefficients (feature -> weight):\")\n",
        "for name, coef in zip(feature_cols, lin_reg.coef_):\n",
        "    print(f\"{name}: {coef:.4f}\")\n",
        "print(\"Intercept:\", lin_reg.intercept_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ë–∞–∑–æ–≤–∞—è –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –Ω–∞ —Ç—Ä—ë—Ö –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö (TotalQuantity, NumLines, MeanPrice) –ø–æ–∫–∞–∑–∞–ª–∞ —Å—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ: MAE ‚âà 215.55, RMSE ‚âà 605.22,\n",
        "ùëÖ\n",
        "2\n",
        "‚âà\n",
        "0.63\n",
        "R\n",
        "2\n",
        "‚âà0.63. –ú–æ–¥–µ–ª—å —É–ª–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—â–∏–π —Ä–æ—Å—Ç —Å—É–º–º—ã —á–µ–∫–∞ —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏ —á–∏—Å–ª–∞ –ø–æ–∑–∏—Ü–∏–π, –Ω–æ –∑–∞–º–µ—Ç–Ω–æ —É—Å—Ç—É–ø–∞–µ—Ç KNN –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏. –í –¥–∞–ª—å–Ω–µ–π—à–µ–º –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ü–µ–ª–µ—Å–æ–æ–±—Ä–∞–∑–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ TotalCheck, –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –Ω–∞–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞ —Å—á—ë—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö (–Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö) –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."
      ],
      "metadata": {
        "id": "_B8vSXD14fzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "ETiR71x-6Nje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ—Å–ª–µ –±–∞–∑–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Å –ø—Ä–æ—Å—Ç–æ–π –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–µ–π –Ω–∞ —Ç—Ä—ë—Ö –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö (TotalQuantity, NumLines, MeanPrice) –∏–º–µ–µ—Ç —Å–º—ã—Å–ª –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —É–¥–∞—Å—Ç—Å—è –ª–∏ —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –∑–∞ —Å—á—ë—Ç –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∫–æ—Ä–∑–∏–Ω—ã –∏ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–≥–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
        "\n",
        "–î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç regression_data.csv, –≤ –∫–æ—Ç–æ—Ä–æ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–µ–∫–∞ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã:\n",
        "\n",
        "–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ—Ä–∑–∏–Ω—ã:\n",
        "TotalQuantity, NumLines, NumUniqueItems, MeanPrice;\n",
        "\n",
        "–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\n",
        "InvoiceHour, InvoiceDayOfWeek, InvoiceMonth;\n",
        "\n",
        "–±–∏–Ω–∞—Ä–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ IsNewCustomer, –æ—Ç—Ä–∞–∂–∞—é—â–∏–π, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å –Ω–æ–≤—ã–º –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º–æ–º—É –ø–µ—Ä–∏–æ–¥—É;\n",
        "\n",
        "–Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ñ–æ—Ä–º–∞—Ç–∞ qty_<‚Ä¶> –¥–ª—è top-N –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è –≤ —á–µ–∫–∞—Ö —Ç–æ–≤–∞—Ä–æ–≤, –≥–¥–µ –∫–∞–∂–¥—ã–π —Å—Ç–æ–ª–±–µ—Ü –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –µ–¥–∏–Ω–∏—Ü —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —Ç–æ–≤–∞—Ä–∞ –≤ –¥–∞–Ω–Ω–æ–º —á–µ–∫–µ.\n",
        "\n",
        "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –±–∞–∑–æ–≤–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞, –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –ª–∏–Ω–µ–π–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
        "\n",
        "—á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é StandardScaler, —á—Ç–æ —É–ª—É—á—à–∞–µ—Ç —á–∏—Å–ª–µ–Ω–Ω—É—é —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º–∏ –∑–Ω–∞—á–µ–Ω–∏–π;\n",
        "\n",
        "–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ Country –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è –º–µ—Ç–æ–¥–æ–º One-Hot Encoding (OneHotEncoder), —á—Ç–æ–±—ã –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—Ä–∞–Ω–µ –±—ã–ª–∞ —É—á—Ç–µ–Ω–∞ –≤ –º–æ–¥–µ–ª–∏ –±–µ–∑ –≤–≤–µ–¥–µ–Ω–∏—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏;\n",
        "\n",
        "—Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è (Invoice, CustomerID, InvoiceDate) –Ω–µ —É—á–∞—Å—Ç–≤—É—é—Ç –≤ –æ–±—É—á–µ–Ω–∏–∏ –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫–∞–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–µ–π.\n",
        "\n",
        "–¢–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–∞–∑–æ–≤–æ–π –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ –ø—Ä–æ—Å—Ç—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–∞—Ö —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–º –∏ —Ç—â–∞—Ç–µ–ª—å–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."
      ],
      "metadata": {
        "id": "tx-yDGH96MHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/–£—á–µ–±–∞/–§—Ä–µ–∏ÃÜ–º–≤–æ—Ä–∫–∏/data\")\n",
        "REG_PATH = DATA_DIR / \"regression_data_hard.csv\"\n",
        "\n",
        "reg_imp = pd.read_csv(REG_PATH)\n",
        "\n",
        "print(\"Improved regression dataset shape:\", reg_imp.shape)\n",
        "print(reg_imp.head())\n",
        "\n",
        "target_col = \"TotalCheck\"\n",
        "exclude_cols = [\"Invoice\", \"CustomerID\", \"InvoiceDate\", target_col]\n",
        "\n",
        "feature_cols = [c for c in reg_imp.columns if c not in exclude_cols]\n",
        "\n",
        "print(\"\\nNumber of feature columns:\", len(feature_cols))\n",
        "print(\"Example feature columns:\", feature_cols[:10])\n",
        "\n",
        "X = reg_imp[feature_cols]\n",
        "y = reg_imp[target_col].values\n",
        "\n",
        "print(\"\\nFeature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "numeric_features = [c for c in feature_cols if c != \"Country\"]\n",
        "categorical_features = [\"Country\"] if \"Country\" in feature_cols else []\n",
        "\n",
        "transformers = []\n",
        "if numeric_features:\n",
        "    transformers.append((\"num\", StandardScaler(), numeric_features))\n",
        "if categorical_features:\n",
        "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=transformers)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "lin_pipe = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", LinearRegression()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "lin_pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lin_pipe.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Linear Regression (improved feature set + scaling + Country OHE) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-WhAReB4fIY",
        "outputId": "4d70a511-1985-490f-f684-7d3e135630a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved regression dataset shape: (39574, 113)\n",
            "   Invoice  CustomerID         Country          InvoiceDate  TotalCheck  \\\n",
            "0   491725     12346.0  United Kingdom  2009-12-14 08:34:00        45.0   \n",
            "1   491742     12346.0  United Kingdom  2009-12-14 11:00:00        22.5   \n",
            "2   491744     12346.0  United Kingdom  2009-12-14 11:02:00        22.5   \n",
            "3   492718     12346.0  United Kingdom  2009-12-18 10:47:00        22.5   \n",
            "4   492722     12346.0  United Kingdom  2009-12-18 10:55:00         1.0   \n",
            "\n",
            "   TotalQuantity  NumLines  NumUniqueItems  MeanPrice  InvoiceHour  ...  \\\n",
            "0             10         1               1        4.5            8  ...   \n",
            "1              5         1               1        4.5           11  ...   \n",
            "2              5         1               1        4.5           11  ...   \n",
            "3              5         1               1        4.5           10  ...   \n",
            "4              1         1               1        1.0           10  ...   \n",
            "\n",
            "   qty_ANTIQUE_SILVER_TEA_GLASS_ETCHED  qty_HANGING_HEART_ZINC_T_LIGHT_HOLDER  \\\n",
            "0                                  0.0                                    0.0   \n",
            "1                                  0.0                                    0.0   \n",
            "2                                  0.0                                    0.0   \n",
            "3                                  0.0                                    0.0   \n",
            "4                                  0.0                                    0.0   \n",
            "\n",
            "   qty_HANGING_HEART_JAR_T_LIGHT_HOLDER  qty_60_TEATIME_FAIRY_CAKE_CASES  \\\n",
            "0                                   0.0                              0.0   \n",
            "1                                   0.0                              0.0   \n",
            "2                                   0.0                              0.0   \n",
            "3                                   0.0                              0.0   \n",
            "4                                   0.0                              0.0   \n",
            "\n",
            "   qty_72_SWEETHEART_FAIRY_CAKE_CASES  qty_JUMBO_BAG_RED_RETROSPOT  \\\n",
            "0                                 0.0                          0.0   \n",
            "1                                 0.0                          0.0   \n",
            "2                                 0.0                          0.0   \n",
            "3                                 0.0                          0.0   \n",
            "4                                 0.0                          0.0   \n",
            "\n",
            "   qty_JUMBO_BAG_BAROQUE_BLACK_WHITE  qty_JUMBO_BAG_STRAWBERRY  \\\n",
            "0                                0.0                       0.0   \n",
            "1                                0.0                       0.0   \n",
            "2                                0.0                       0.0   \n",
            "3                                0.0                       0.0   \n",
            "4                                0.0                       0.0   \n",
            "\n",
            "   qty_WHITE_HANGING_HEART_T_LIGHT_HOLDER  qty_HAND_OVER_THE_CHOCOLATE_SIGN  \n",
            "0                                     0.0                               0.0  \n",
            "1                                     0.0                               0.0  \n",
            "2                                     0.0                               0.0  \n",
            "3                                     0.0                               0.0  \n",
            "4                                     0.0                               0.0  \n",
            "\n",
            "[5 rows x 113 columns]\n",
            "\n",
            "Number of feature columns: 109\n",
            "Example feature columns: ['Country', 'TotalQuantity', 'NumLines', 'NumUniqueItems', 'MeanPrice', 'InvoiceHour', 'InvoiceDayOfWeek', 'InvoiceMonth', 'IsNewCustomer', 'qty_DOORMAT_RED_RETROSPOT']\n",
            "\n",
            "Feature matrix shape: (39574, 109)\n",
            "Target vector shape: (39574,)\n",
            "\n",
            "Train size: 31659\n",
            "Test size: 7915\n",
            "\n",
            "=== Linear Regression (improved feature set + scaling + Country OHE) ===\n",
            "MAE:  181.62\n",
            "RMSE: 812.59\n",
            "R¬≤:   0.5968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WhoF6QOh9hWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "q_high = reg_imp[target_col].quantile(0.995)\n",
        "mask = reg_imp[target_col] <= q_high\n",
        "reg_trim = reg_imp[mask].reset_index(drop=True)\n",
        "\n",
        "print(\"Original rows:\", len(reg_imp))\n",
        "print(\"Trimmed rows:\", len(reg_trim))\n",
        "print(\"Cutoff (99.5% quantile) TotalCheck:\", q_high)\n",
        "\n",
        "exclude_cols = [\"Invoice\", \"CustomerID\", \"InvoiceDate\", target_col]\n",
        "feature_cols = [c for c in reg_trim.columns if c not in exclude_cols]\n",
        "\n",
        "print(\"\\nNumber of feature columns:\", len(feature_cols))\n",
        "print(\"Example feature columns:\", feature_cols[:10])\n",
        "\n",
        "X = reg_trim[feature_cols]\n",
        "y = reg_trim[target_col].values\n",
        "\n",
        "print(\"\\nFeature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "numeric_features = [c for c in feature_cols if c != \"Country\"]\n",
        "categorical_features = [\"Country\"] if \"Country\" in feature_cols else []\n",
        "\n",
        "transformers = []\n",
        "if numeric_features:\n",
        "    transformers.append((\"num\", StandardScaler(), numeric_features))\n",
        "if categorical_features:\n",
        "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=transformers)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "lin_pipe_trim = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", LinearRegression()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "lin_pipe_trim.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lin_pipe_trim.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Linear Regression (improved features, trimmed target + scaling + Country OHE) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEe3qZT39hkB",
        "outputId": "015e6454-b449-40f2-f119-875ce48b3926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 39574\n",
            "Trimmed rows: 39376\n",
            "Cutoff (99.5% quantile) TotalCheck: 5739.156000000027\n",
            "\n",
            "Number of feature columns: 109\n",
            "Example feature columns: ['Country', 'TotalQuantity', 'NumLines', 'NumUniqueItems', 'MeanPrice', 'InvoiceHour', 'InvoiceDayOfWeek', 'InvoiceMonth', 'IsNewCustomer', 'qty_DOORMAT_RED_RETROSPOT']\n",
            "\n",
            "Feature matrix shape: (39376, 109)\n",
            "Target vector shape: (39376,)\n",
            "\n",
            "Train size: 31500\n",
            "Test size: 7876\n",
            "\n",
            "=== Linear Regression (improved features, trimmed target + scaling + Country OHE) ===\n",
            "MAE:  115.99\n",
            "RMSE: 229.30\n",
            "R¬≤:   0.8306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π TotalCheck (–æ–±—Ä–µ–∑–∫–∞ –ø–æ 99.5-–º—É –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—é) –∏ –æ–±—É—á–µ–Ω–∏—è –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ One-Hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º Country –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —É–ª—É—á—à–∏–ª–æ—Å—å: MAE ‚âà 115.99, RMSE ‚âà 229.30,\n",
        "ùëÖ\n",
        "2\n",
        "‚âà\n",
        "0.83\n",
        "R\n",
        "2\n",
        "‚âà0.83. –ú–æ–¥–µ–ª—å —Å—Ç–∞–ª–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ç–æ—á–Ω–µ–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –±–∞–∑–æ–≤–æ–π –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–µ–π –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É —Å –ª—É—á—à–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ KNN. –î–∞–ª–µ–µ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –∫–∞–∫ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–≤–ª–∏—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (Ridge, Lasso, ElasticNet)."
      ],
      "metadata": {
        "id": "Q9pFTAQBACMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "q_high = reg_imp[target_col].quantile(0.995)\n",
        "mask = reg_imp[target_col] <= q_high\n",
        "reg_trim = reg_imp[mask].reset_index(drop=True)\n",
        "\n",
        "print(\"Original rows:\", len(reg_imp))\n",
        "print(\"Trimmed rows:\", len(reg_trim))\n",
        "print(\"Cutoff (99.5% quantile) TotalCheck:\", q_high)\n",
        "\n",
        "exclude_cols = [\"Invoice\", \"CustomerID\", \"InvoiceDate\", target_col]\n",
        "feature_cols = [c for c in reg_trim.columns if c not in exclude_cols]\n",
        "\n",
        "print(\"\\nNumber of feature columns:\", len(feature_cols))\n",
        "print(\"Example feature columns:\", feature_cols[:10])\n",
        "\n",
        "X = reg_trim[feature_cols]\n",
        "y = reg_trim[target_col].values\n",
        "\n",
        "print(\"\\nFeature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "numeric_features = [c for c in feature_cols if c != \"Country\"]\n",
        "categorical_features = [\"Country\"] if \"Country\" in feature_cols else []\n",
        "\n",
        "transformers = []\n",
        "if numeric_features:\n",
        "    transformers.append((\"num\", StandardScaler(), numeric_features))\n",
        "if categorical_features:\n",
        "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=transformers)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "def eval_model(model, name):\n",
        "    pipe = Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\"model\", model),\n",
        "        ]\n",
        "    )\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"MAE:  {mae:.2f}\")\n",
        "    print(f\"RMSE: {rmse:.2f}\")\n",
        "    print(f\"R¬≤:   {r2:.4f}\")\n",
        "    return pipe\n",
        "\n",
        "lin_model = eval_model(LinearRegression(), \"LinearRegression (baseline, trimmed + scaling + OHE)\")\n",
        "\n",
        "ridge_model = eval_model(Ridge(alpha=1.0), \"Ridge (alpha=1.0)\")\n",
        "ridge_model_01 = eval_model(Ridge(alpha=0.1), \"Ridge (alpha=0.1)\")\n",
        "ridge_model_10 = eval_model(Ridge(alpha=10.0), \"Ridge (alpha=10.0)\")\n",
        "\n",
        "lasso_model = eval_model(Lasso(alpha=0.001, max_iter=10000), \"Lasso (alpha=0.001)\")\n",
        "lasso_model_01 = eval_model(Lasso(alpha=0.01, max_iter=10000), \"Lasso (alpha=0.01)\")\n",
        "lasso_model_1 = eval_model(Lasso(alpha=0.1, max_iter=10000), \"Lasso (alpha=0.1)\")\n",
        "\n",
        "enet_model = eval_model(ElasticNet(alpha=0.001, l1_ratio=0.5, max_iter=10000), \"ElasticNet (alpha=0.001, l1_ratio=0.5)\")\n",
        "enet_model_01 = eval_model(ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=10000), \"ElasticNet (alpha=0.01, l1_ratio=0.5)\")\n",
        "enet_model_1 = eval_model(ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000), \"ElasticNet (alpha=0.1, l1_ratio=0.5)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ1BIrV5_Cbu",
        "outputId": "ced80d38-b460-4ed0-de80-05f48416162b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 39574\n",
            "Trimmed rows: 39376\n",
            "Cutoff (99.5% quantile) TotalCheck: 5739.156000000027\n",
            "\n",
            "Number of feature columns: 109\n",
            "Example feature columns: ['Country', 'TotalQuantity', 'NumLines', 'NumUniqueItems', 'MeanPrice', 'InvoiceHour', 'InvoiceDayOfWeek', 'InvoiceMonth', 'IsNewCustomer', 'qty_DOORMAT_RED_RETROSPOT']\n",
            "\n",
            "Feature matrix shape: (39376, 109)\n",
            "Target vector shape: (39376,)\n",
            "\n",
            "Train size: 31500\n",
            "Test size: 7876\n",
            "\n",
            "=== LinearRegression (baseline, trimmed + scaling + OHE) ===\n",
            "MAE:  115.99\n",
            "RMSE: 229.30\n",
            "R¬≤:   0.8306\n",
            "\n",
            "=== Ridge (alpha=1.0) ===\n",
            "MAE:  116.01\n",
            "RMSE: 229.26\n",
            "R¬≤:   0.8307\n",
            "\n",
            "=== Ridge (alpha=0.1) ===\n",
            "MAE:  115.99\n",
            "RMSE: 229.29\n",
            "R¬≤:   0.8306\n",
            "\n",
            "=== Ridge (alpha=10.0) ===\n",
            "MAE:  116.55\n",
            "RMSE: 229.82\n",
            "R¬≤:   0.8298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.904e+07, tolerance: 1.051e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Lasso (alpha=0.001) ===\n",
            "MAE:  115.99\n",
            "RMSE: 229.29\n",
            "R¬≤:   0.8306\n",
            "\n",
            "=== Lasso (alpha=0.01) ===\n",
            "MAE:  115.97\n",
            "RMSE: 229.20\n",
            "R¬≤:   0.8307\n",
            "\n",
            "=== Lasso (alpha=0.1) ===\n",
            "MAE:  116.18\n",
            "RMSE: 229.35\n",
            "R¬≤:   0.8305\n",
            "\n",
            "=== ElasticNet (alpha=0.001, l1_ratio=0.5) ===\n",
            "MAE:  116.82\n",
            "RMSE: 230.09\n",
            "R¬≤:   0.8294\n",
            "\n",
            "=== ElasticNet (alpha=0.01, l1_ratio=0.5) ===\n",
            "MAE:  117.90\n",
            "RMSE: 231.09\n",
            "R¬≤:   0.8279\n",
            "\n",
            "=== ElasticNet (alpha=0.1, l1_ratio=0.5) ===\n",
            "MAE:  118.67\n",
            "RMSE: 229.98\n",
            "R¬≤:   0.8296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ù–∞ —É—Å–µ—á—ë–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (–æ–±—Ä–µ–∑–∫–∞ –ø–æ 99.5-–º—É –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—é TotalCheck) —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ One-Hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º Country –±–∞–∑–æ–≤–∞—è –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ø–æ–∫–∞–∑–∞–ª–∞ –∫–∞—á–µ—Å—Ç–≤–æ MAE ‚âà 115.99, RMSE ‚âà 229.30, R2‚âà0.83. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –≤ –≤–∏–¥–µ Ridge, Lasso –∏ ElasticNet –Ω–µ –ø—Ä–∏–≤–µ–ª–æ –∫ –∑–∞–º–µ—Ç–Ω–æ–º—É —É–ª—É—á—à–µ–Ω–∏—é –º–µ—Ç—Ä–∏–∫: –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥–∞—é—Ç –æ—á–µ–Ω—å –±–ª–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è MAE/RMSE/R¬≤, –∞ –Ω–∞–∏–ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç Lasso —Å Œ±=0.01 (MAE ‚âà 115.97, RMSE ‚âà 229.20,\n",
        "ùëÖ2‚âà0.83). –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Ä–µ–≥—É–ª—è—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –Ω–µ —É–ª—É—á—à–∞—é—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –æ–±—ã—á–Ω–æ–π –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–µ–π –∏ –º–æ–≥—É—Ç —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å—Å—è —Å–∫–æ—Ä–µ–µ –∫–∞–∫ —Å—Ä–µ–¥—Å—Ç–≤–æ –ª—ë–≥–∫–æ–π —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –∏ —É–ø—Ä–æ—â–µ–Ω–∏—è –º–æ–¥–µ–ª–∏, —á–µ–º –∫–∞–∫ —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–æ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å."
      ],
      "metadata": {
        "id": "w7mzLnmTRu16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–î–∞–ª–µ–µ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è –≥–∏–ø–æ—Ç–µ–∑–∞ –æ —Ç–æ–º, —á—Ç–æ –¥–ª—è –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö, –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ñ–ª–∞–≥–∞ IsNewCustomer, –∞ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ qty_* –ª–∏—à—å —Ä–∞–∑–¥—É–≤–∞—é—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–µ–∑ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏—Ä–æ—Å—Ç–∞ –∫–∞—á–µ—Å—Ç–≤–∞. –î–ª—è —ç—Ç–æ–≥–æ –∏–∑ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —É–¥–∞–ª—è—é—Ç—Å—è –≤—Å–µ —Å—Ç–æ–ª–±—Ü—ã qty_*, –∞ –º–æ–¥–µ–ª—å –ø–æ–≤—Ç–æ—Ä–Ω–æ –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ —É—Å–µ—á—ë–Ω–Ω–æ–º –ø–æ —Ç–∞—Ä–≥–µ—Ç—É –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –∏ One-Hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è Country)."
      ],
      "metadata": {
        "id": "Ahksxp-kVcxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "q_high = reg_imp[target_col].quantile(0.995)\n",
        "mask = reg_imp[target_col] <= q_high\n",
        "reg_trim = reg_imp[mask].reset_index(drop=True)\n",
        "\n",
        "print(\"Original rows:\", len(reg_imp))\n",
        "print(\"Trimmed rows:\", len(reg_trim))\n",
        "print(\"Cutoff (99.5% quantile) TotalCheck:\", q_high)\n",
        "\n",
        "exclude_base = [\"Invoice\", \"CustomerID\", \"InvoiceDate\", target_col]\n",
        "qty_cols = [c for c in reg_trim.columns if c.startswith(\"qty_\")]\n",
        "exclude_cols = exclude_base + qty_cols\n",
        "\n",
        "feature_cols = [c for c in reg_trim.columns if c not in exclude_cols]\n",
        "\n",
        "print(\"\\nNumber of feature columns (no qty_*):\", len(feature_cols))\n",
        "print(\"Example feature columns:\", feature_cols[:10])\n",
        "\n",
        "X = reg_trim[feature_cols]\n",
        "y = reg_trim[target_col].values\n",
        "\n",
        "print(\"\\nFeature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "numeric_features = [c for c in feature_cols if c != \"Country\"]\n",
        "categorical_features = [\"Country\"] if \"Country\" in feature_cols else []\n",
        "\n",
        "transformers = []\n",
        "if numeric_features:\n",
        "    transformers.append((\"num\", StandardScaler(), numeric_features))\n",
        "if categorical_features:\n",
        "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=transformers)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "lin_pipe_no_qty = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", LinearRegression()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "lin_pipe_no_qty.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lin_pipe_no_qty.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Linear Regression (trimmed target, no qty_*, scaling + Country OHE) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37x9S26CS7dp",
        "outputId": "1a4186f6-aa0d-4a35-bb10-99353de73825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 39574\n",
            "Trimmed rows: 39376\n",
            "Cutoff (99.5% quantile) TotalCheck: 5739.156000000027\n",
            "\n",
            "Number of feature columns (no qty_*): 9\n",
            "Example feature columns: ['Country', 'TotalQuantity', 'NumLines', 'NumUniqueItems', 'MeanPrice', 'InvoiceHour', 'InvoiceDayOfWeek', 'InvoiceMonth', 'IsNewCustomer']\n",
            "\n",
            "Feature matrix shape: (39376, 9)\n",
            "Target vector shape: (39376,)\n",
            "\n",
            "Train size: 31500\n",
            "Test size: 7876\n",
            "\n",
            "=== Linear Regression (trimmed target, no qty_*, scaling + Country OHE) ===\n",
            "MAE:  149.87\n",
            "RMSE: 310.62\n",
            "R¬≤:   0.6891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ñ–æ—Ä–º–∞—Ç–∞ qty_* –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–ª—å–∫–æ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –∫–æ—Ä–∑–∏–Ω—ã, –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, IsNewCustomer –∏ Country –∫–∞—á–µ—Å—Ç–≤–æ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∑–∞–º–µ—Ç–Ω–æ —Å–Ω–∏–∑–∏–ª–æ—Å—å. –≠—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –¥–ª—è –ª–∏–Ω–µ–π–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–∞ –∫–æ—Ä–∑–∏–Ω—ã —á–µ—Ä–µ–∑ qty_* –¥–∞—ë—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≤–∫–ª–∞–¥ –≤ –∫–∞—á–µ—Å—Ç–≤–æ, –∏ –∏—Ö –ø–æ–ª–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –∑–∞–º–µ—Ç–Ω–æ–π –ø–æ—Ç–µ—Ä–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —á–µ–∫–∞."
      ],
      "metadata": {
        "id": "9qbmxyyEVFuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–ò–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞"
      ],
      "metadata": {
        "id": "_Np074fcW3bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ ¬´–æ–±—ã—á–Ω—ã—Ö¬ª –¥–∞–Ω–Ω—ã—Ö, —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –±–µ–π–∑–ª–∞–π–Ω–∞: –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∞–≥—Ä–µ–≥–∞—Ç—ã –ø–æ —á–µ–∫—É (TotalQuantity, NumLines, MeanPrice), –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π ‚Äí TotalCheck. –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –±–µ–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–±—Ä–æ—Å–æ–≤, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–ø—Ä—è–º—É—é —Å—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞—Å—Ç–æ–º–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –±–∞–∑–æ–≤–æ–π –±–∏–±–ª–∏–æ—Ç–µ—á–Ω–æ–π –º–æ–¥–µ–ª—å—é."
      ],
      "metadata": {
        "id": "cLbKUT10k1yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "class MyLinearRegression:\n",
        "    def __init__(self, fit_intercept=True):\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        y = np.asarray(y, dtype=float)\n",
        "\n",
        "        if X.ndim != 2:\n",
        "            raise ValueError(\"X must be 2D array of shape (n_samples, n_features)\")\n",
        "        if y.ndim != 1:\n",
        "            raise ValueError(\"y must be 1D array of shape (n_samples,)\")\n",
        "\n",
        "        if X.shape[0] != y.shape[0]:\n",
        "            raise ValueError(\"X and y must have the same number of samples\")\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            ones = np.ones((X.shape[0], 1))\n",
        "            X_ext = np.hstack([ones, X])\n",
        "        else:\n",
        "            X_ext = X\n",
        "\n",
        "        XtX = X_ext.T @ X_ext\n",
        "        XtX_pinv = np.linalg.pinv(XtX)\n",
        "        Xt_y = X_ext.T @ y\n",
        "        w = XtX_pinv @ Xt_y\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            self.intercept_ = w[0]\n",
        "            self.coef_ = w[1:]\n",
        "        else:\n",
        "            self.intercept_ = 0.0\n",
        "            self.coef_ = w\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.coef_ is None:\n",
        "            raise RuntimeError(\"You must call fit() before predict().\")\n",
        "\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        if X.ndim == 1:\n",
        "            X = X.reshape(1, -1)\n",
        "\n",
        "        y_hat = X @ self.coef_\n",
        "        if self.fit_intercept:\n",
        "            y_hat = y_hat + self.intercept_\n",
        "        return y_hat\n",
        "\n",
        "\n",
        "print(\"Simple regression dataset shape:\", reg_simple.shape)\n",
        "print(reg_simple.head())\n",
        "\n",
        "feature_cols = [\"TotalQuantity\", \"NumLines\", \"MeanPrice\"]\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "X = reg_simple[feature_cols].values\n",
        "y = reg_simple[target_col].values\n",
        "\n",
        "print(\"\\nFeature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "my_lin = MyLinearRegression(fit_intercept=True)\n",
        "my_lin.fit(X_train, y_train)\n",
        "\n",
        "y_pred = my_lin.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Custom Linear Regression (simple features, no scaling) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n",
        "\n",
        "print(\"\\nCoefficients (feature -> weight):\")\n",
        "for name, coef in zip(feature_cols, my_lin.coef_):\n",
        "    print(f\"{name}: {coef:.4f}\")\n",
        "print(\"Intercept:\", my_lin.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Y8KkPqk2Nk",
        "outputId": "e644338c-a17c-4b5c-8a0d-69cea490f61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple regression dataset shape: (39574, 6)\n",
            "   Invoice  CustomerID  TotalCheck  TotalQuantity  NumLines  MeanPrice\n",
            "0   489434     13085.0      505.30            166         8   4.081250\n",
            "1   489435     13085.0      145.80             60         4   2.625000\n",
            "2   489436     13078.0      630.33            193        19   3.730526\n",
            "3   489437     15362.0      310.75            145        23   3.628261\n",
            "4   489438     18102.0     2286.24            826        17   2.591176\n",
            "\n",
            "Feature matrix shape: (39574, 3)\n",
            "Target vector shape: (39574,)\n",
            "\n",
            "Train size: 31659\n",
            "Test size: 7915\n",
            "\n",
            "=== Custom Linear Regression (simple features, no scaling) ===\n",
            "MAE:  215.55\n",
            "RMSE: 605.22\n",
            "R¬≤:   0.6301\n",
            "\n",
            "Coefficients (feature -> weight):\n",
            "TotalQuantity: 0.7245\n",
            "NumLines: 6.6625\n",
            "MeanPrice: 7.5319\n",
            "Intercept: 93.43906975326118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (MyLinearRegression) –Ω–∞ –ø—Ä–æ—Å—Ç–æ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (TotalQuantity, NumLines, MeanPrice) –ø–æ–∫–∞–∑–∞–ª–∞ —Ç–µ –∂–µ –º–µ—Ç—Ä–∏–∫–∏, —á—Ç–æ –∏ –º–æ–¥–µ–ª—å LinearRegression –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ sklearn, –∞ —Ç–∞–∫–∂–µ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –∏ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ —á–ª–µ–Ω–∞. –≠—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –±–∏–±–ª–∏–æ—Ç–µ—á–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π."
      ],
      "metadata": {
        "id": "lyzK3rcElY_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –±–∏–±–ª–∏–æ—Ç–µ—á–Ω–æ–π –º–æ–¥–µ–ª—å—é LinearRegression –±—ã–ª–∞ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –∫–∞—Å—Ç–æ–º–Ω–∞—è –≤–µ—Ä—Å–∏—è –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –∫ —É–ª—É—á—à–µ–Ω–Ω–æ–º—É –±–µ–π–∑–ª–∞–π–Ω—É: –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ —Ç–æ–≤–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (qty_*), –ø—Ä–∏–∑–Ω–∞–∫ IsNewCustomer, –∞ —Ç–∞–∫–∂–µ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π One-Hot –ø—Ä–∏–∑–Ω–∞–∫ Country. –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è TotalCheck –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —É—Å–µ—á–µ–Ω–∞ –ø–æ 99.5-–º—É –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—é, —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è, –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è, –ø–æ—Å–ª–µ —á–µ–≥–æ –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –ø–æ–ª—É—á–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."
      ],
      "metadata": {
        "id": "pWJOsYawoQCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "class MyLinearRegression:\n",
        "    def __init__(self, fit_intercept=True):\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        y = np.asarray(y, dtype=float)\n",
        "\n",
        "        if X.ndim != 2:\n",
        "            raise ValueError(\"X must be 2D array of shape (n_samples, n_features)\")\n",
        "        if y.ndim != 1:\n",
        "            raise ValueError(\"y must be 1D array of shape (n_samples,)\")\n",
        "\n",
        "        if X.shape[0] != y.shape[0]:\n",
        "            raise ValueError(\"X and y must have the same number of samples\")\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            ones = np.ones((X.shape[0], 1))\n",
        "            X_ext = np.hstack([ones, X])\n",
        "        else:\n",
        "            X_ext = X\n",
        "\n",
        "        XtX = X_ext.T @ X_ext\n",
        "        XtX_pinv = np.linalg.pinv(XtX)\n",
        "        Xt_y = X_ext.T @ y\n",
        "        w = XtX_pinv @ Xt_y\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            self.intercept_ = w[0]\n",
        "            self.coef_ = w[1:]\n",
        "        else:\n",
        "            self.intercept_ = 0.0\n",
        "            self.coef_ = w\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.coef_ is None:\n",
        "            raise RuntimeError(\"You must call fit() before predict().\")\n",
        "\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        if X.ndim == 1:\n",
        "            X = X.reshape(1, -1)\n",
        "\n",
        "        y_hat = X @ self.coef_\n",
        "        if self.fit_intercept:\n",
        "            y_hat = y_hat + self.intercept_\n",
        "        return y_hat\n",
        "\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "q_high = reg_imp[target_col].quantile(0.995)\n",
        "mask = reg_imp[target_col] <= q_high\n",
        "reg_trim = reg_imp[mask].reset_index(drop=True)\n",
        "\n",
        "print(\"Original rows:\", len(reg_imp))\n",
        "print(\"Trimmed rows:\", len(reg_trim))\n",
        "print(\"Cutoff (99.5% quantile) TotalCheck:\", q_high)\n",
        "\n",
        "exclude_cols = [\"Invoice\", \"CustomerID\", \"InvoiceDate\", target_col]\n",
        "feature_cols = [c for c in reg_trim.columns if c not in exclude_cols]\n",
        "\n",
        "print(\"\\nNumber of feature columns:\", len(feature_cols))\n",
        "print(\"Example feature columns:\", feature_cols[:10])\n",
        "\n",
        "X = reg_trim[feature_cols]\n",
        "y = reg_trim[target_col].values\n",
        "\n",
        "print(\"\\nRaw feature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "numeric_features = [c for c in feature_cols if c != \"Country\"]\n",
        "categorical_features = [\"Country\"] if \"Country\" in feature_cols else []\n",
        "\n",
        "transformers = []\n",
        "if numeric_features:\n",
        "    transformers.append((\"num\", StandardScaler(), numeric_features))\n",
        "if categorical_features:\n",
        "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=transformers)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "X_train_proc = preprocessor.fit_transform(X_train)\n",
        "X_test_proc = preprocessor.transform(X_test)\n",
        "\n",
        "print(\"Processed train shape:\", X_train_proc.shape)\n",
        "print(\"Processed test shape:\", X_test_proc.shape)\n",
        "\n",
        "my_lin_imp = MyLinearRegression(fit_intercept=True)\n",
        "my_lin_imp.fit(X_train_proc, y_train)\n",
        "\n",
        "y_pred = my_lin_imp.predict(X_test_proc)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Custom Linear Regression (improved baseline: trimmed target + scaling + full features) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir7fsJzToREA",
        "outputId": "ece47de7-7597-42bb-9771-c6b6b386864b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 39574\n",
            "Trimmed rows: 39376\n",
            "Cutoff (99.5% quantile) TotalCheck: 5739.156000000027\n",
            "\n",
            "Number of feature columns: 109\n",
            "Example feature columns: ['Country', 'TotalQuantity', 'NumLines', 'NumUniqueItems', 'MeanPrice', 'InvoiceHour', 'InvoiceDayOfWeek', 'InvoiceMonth', 'IsNewCustomer', 'qty_DOORMAT_RED_RETROSPOT']\n",
            "\n",
            "Raw feature matrix shape: (39376, 109)\n",
            "Target vector shape: (39376,)\n",
            "\n",
            "Train size: 31500\n",
            "Test size: 7876\n",
            "Processed train shape: (31500, 151)\n",
            "Processed test shape: (7876, 151)\n",
            "\n",
            "=== Custom Linear Regression (improved baseline: trimmed target + scaling + full features) ===\n",
            "MAE:  115.99\n",
            "RMSE: 229.30\n",
            "R¬≤:   0.8306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ö–∞—Å—Ç–æ–º–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–º –±–µ–π–∑–ª–∞–π–Ω–µ (—É—Å–µ—á—ë–Ω–Ω—ã–π –ø–æ 99.5-–º—É –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—é —Ç–∞—Ä–≥–µ—Ç, –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, One-Hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ Country, –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ —Ç–æ–≤–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏) –ø–æ–∫–∞–∑–∞–ª–∞ –º–µ—Ç—Ä–∏–∫–∏, –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±–∏–±–ª–∏–æ—Ç–µ—á–Ω–æ–π –º–æ–¥–µ–ª–∏ LinearRegression –ø—Ä–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–µ, —á—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."
      ],
      "metadata": {
        "id": "QiVOVicko0y8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è"
      ],
      "metadata": {
        "id": "ToGqcEm3li11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "crO13V5cmrq6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGLjY6aAmrq8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "fd1ewdMnmrq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–ò–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞"
      ],
      "metadata": {
        "id": "6_le72cGmrq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "FS7yNUJOmrq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "7IitQ7_Nmrq_"
      }
    }
  ]
}