{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kqhAkmWybqWc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#–†–µ–≥—Ä–µ—Å—Å–∏—è"
      ],
      "metadata": {
        "id": "IhUzJMAQk9oH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "kqhAkmWybqWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ù–∞ –ø–µ—Ä–≤–æ–º —ç—Ç–∞–ø–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –±—ã–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–∞—è –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏. –ò—Å—Ö–æ–¥–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω—ã –¥–æ —É—Ä–æ–≤–Ω—è —á–µ–∫–∞: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ Invoice –≤—ã—á–∏—Å–ª—è–ª–∏—Å—å —Å—É–º–º–∞—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ–∫—É–ø–∫–∏ (TotalCheck), –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—É–ø–ª–µ–Ω–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü —Ç–æ–≤–∞—Ä–∞ (TotalQuantity), —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫ –≤ —á–µ–∫–µ (NumLines) –∏ —Å—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –æ–¥–Ω–æ–π –µ–¥–∏–Ω–∏—Ü—ã (MeanPrice). –í –∫–∞—á–µ—Å—Ç–≤–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –±—ã–ª –≤—ã–±—Ä–∞–Ω –º–µ—Ç–æ–¥ k-–±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π (KNN) —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é:\n",
        "k=5, —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ —Å–æ—Å–µ–¥–µ–π –∏ –µ–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ. –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ —ç—Ç–æ–º –ø—Ä–æ—Å—Ç–æ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –±–µ–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è, –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π. –¶–µ–ª—å –¥–∞–Ω–Ω–æ–≥–æ —à–∞–≥–∞ ‚Äì –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–Ω—É—é —Ç–æ—á–∫—É (baseline), —Å –∫–æ—Ç–æ—Ä–æ–π –¥–∞–ª–µ–µ –º–æ–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —É–ª—É—á—à–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –º–æ–¥–µ–ª–µ–π —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–æ–º."
      ],
      "metadata": {
        "id": "ZKDLyVNqdC-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/–£—á–µ–±–∞/–§—Ä–µ–∏ÃÜ–º–≤–æ—Ä–∫–∏/data\")\n",
        "SIMPLE_REG_PATH = DATA_DIR / \"regression_data_simple.csv\"\n",
        "\n",
        "reg_simple = pd.read_csv(SIMPLE_REG_PATH)\n",
        "\n",
        "print(\"Simple regression dataset shape:\", reg_simple.shape)\n",
        "print(reg_simple.head())\n",
        "\n",
        "feature_cols = [\"TotalQuantity\", \"NumLines\", \"MeanPrice\"]\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "X = reg_simple[feature_cols].values\n",
        "y = reg_simple[target_col].values\n",
        "\n",
        "print(\"\\nFeature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "knn_base = KNeighborsRegressor(\n",
        "    n_neighbors=5,\n",
        "    weights=\"uniform\",\n",
        "    metric=\"minkowski\",\n",
        "    p=2\n",
        ")\n",
        "\n",
        "knn_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn_base.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Baseline KNN regression (simple features) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdommerYdCX0",
        "outputId": "66cfce11-8d56-4f5c-b400-4955cefdf899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple regression dataset shape: (39574, 6)\n",
            "   Invoice  CustomerID  TotalCheck  TotalQuantity  NumLines  MeanPrice\n",
            "0   489434     13085.0      505.30            166         8   4.081250\n",
            "1   489435     13085.0      145.80             60         4   2.625000\n",
            "2   489436     13078.0      630.33            193        19   3.730526\n",
            "3   489437     15362.0      310.75            145        23   3.628261\n",
            "4   489438     18102.0     2286.24            826        17   2.591176\n",
            "\n",
            "Feature matrix shape: (39574, 3)\n",
            "Target vector shape: (39574,)\n",
            "\n",
            "Train size: 31659\n",
            "Test size: 7915\n",
            "\n",
            "=== Baseline KNN regression (simple features) ===\n",
            "MAE:  154.29\n",
            "RMSE: 521.70\n",
            "R¬≤:   0.7252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ—Å–ª–µ –æ—Ü–µ–Ω–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ KNN –Ω–∞ –ø—Ä–æ—Å—Ç–æ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –±–µ–∑ –∫–∞–∫–æ–≥–æ-–ª–∏–±–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –±—ã–ª–æ –ª–æ–≥–∏—á–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–ª–∏—è–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –î–ª—è —ç—Ç–æ–≥–æ –±—ã–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Ç–∞ –∂–µ —Å–∞–º–∞—è –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏ (–ø—Ä–∏–∑–Ω–∞–∫–∏ TotalQuantity, NumLines, MeanPrice –∏ —Ç–∞—Ä–≥–µ—Ç TotalCheck), –Ω–æ –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º KNN –∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º –ø—Ä–∏–º–µ–Ω—è–ª—Å—è StandardScaler, –ø—Ä–∏–≤–æ–¥—è—â–∏–π –∏—Ö –∫ –æ–±—â–µ–º—É –º–∞—Å—à—Ç–∞–±—É."
      ],
      "metadata": {
        "id": "AI0-ynfFfmL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [\"TotalQuantity\", \"NumLines\", \"MeanPrice\"]\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "X = reg_simple[feature_cols]\n",
        "y = reg_simple[target_col].values\n",
        "\n",
        "print(\"\\nFeature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "\n",
        "knn_scaled = Pipeline(\n",
        "    steps=[\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", KNeighborsRegressor(\n",
        "            n_neighbors=5,\n",
        "            weights=\"uniform\",\n",
        "            metric=\"minkowski\",\n",
        "            p=2,\n",
        "        )),\n",
        "    ]\n",
        ")\n",
        "\n",
        "knn_scaled.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = knn_scaled.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Baseline KNN regression WITH scaling (simple features) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuWiitWBrXb2",
        "outputId": "585e3878-f7a5-4407-9063-fabaf9bda2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature matrix shape: (39574, 3)\n",
            "Target vector shape: (39574,)\n",
            "\n",
            "Train size: 31659\n",
            "Test size: 7915\n",
            "\n",
            "=== Baseline KNN regression WITH scaling (simple features) ===\n",
            "MAE:  116.36\n",
            "RMSE: 479.45\n",
            "R¬≤:   0.7679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–¢–æ –µ—Å—Ç—å —Å—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ —Å–æ–∫—Ä–∞—Ç–∏–ª–∞—Å—å, –∞ –¥–æ–ª—è –æ–±—ä—è—Å–Ω—ë–Ω–Ω–æ–π –≤–∞—Ä–∏–∞—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –≤—ã—Ä–æ—Å–ª–∞. –≠—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ –¥–ª—è –º–µ—Ç–æ–¥–∞ k-–±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –Ω–∞–ø—Ä—è–º—É—é –æ–ø–∏—Ä–∞–µ—Ç—Å—è –Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏, –∏ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –º–∞—Å—à—Ç–∞–±—É –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–≥—É—Ç –∏—Å–∫–∞–∂–∞—Ç—å –≥–µ–æ–º–µ—Ç—Ä–∏—é –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞. –í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–∞—ë—Ç –±–æ–ª–µ–µ ¬´—á–µ—Å—Ç–Ω–æ–µ¬ª —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —á–µ–∫–∞–º–∏ –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏."
      ],
      "metadata": {
        "id": "jMmnR8uyrjqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ö–∞–∫ –º—ã –ø–æ–º–Ω–∏–º –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö, –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π TotalCheck –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤—ã—Ä–∞–∂–µ–Ω–Ω—ã–µ –≤—ã–±—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–∏–ª—å–Ω–æ –∏—Å–∫–∞–∂–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω—É –∏ —É—Ö—É–¥—à–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏. –ü–æ—ç—Ç–æ–º—É –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏–º –≥–∏–ø–æ—Ç–µ–∑—É –æ —Ç–æ–º, —á—Ç–æ —É–¥–∞–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª—å–Ω–æ –±–æ–ª—å—à–∏—Ö —á–µ–∫–æ–≤ —É–ª—É—á—à–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: –¥–ª—è —ç—Ç–æ–≥–æ –æ—Ç–±—Ä–æ—Å–∏–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–µ TotalCheck –ø—Ä–µ–≤—ã—à–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 99.5-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)."
      ],
      "metadata": {
        "id": "xOUyu7Yyrr3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_high = reg_simple[\"TotalCheck\"].quantile(0.995)\n",
        "mask = reg_simple[\"TotalCheck\"] <= q_high\n",
        "reg_trim = reg_simple[mask].reset_index(drop=True)\n",
        "\n",
        "X = reg_trim[feature_cols].values\n",
        "y = reg_trim[target_col].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "knn_trim = Pipeline(\n",
        "    steps=[\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", KNeighborsRegressor(\n",
        "            n_neighbors=5,\n",
        "            weights=\"uniform\",\n",
        "            metric=\"minkowski\",\n",
        "            p=2,\n",
        "        )),\n",
        "    ]\n",
        ")\n",
        "\n",
        "knn_trim.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn_trim.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== KNN on trimmed target (TotalCheck <= 99.5 percentile) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n",
        "print(f\"Data size after trim: {len(reg_trim)} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbdL-chDrsKN",
        "outputId": "c7d6a0be-60d4-469e-8897-bc38594be285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== KNN on trimmed target (TotalCheck <= 99.5 percentile) ===\n",
            "MAE:  96.51\n",
            "RMSE: 227.01\n",
            "R¬≤:   0.8472\n",
            "Data size after trim: 39376 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ–ª—É—á–∏–ª–æ—Å—å –≥–æ—Ä–∞–∑–¥–æ –ª—É—á—à–µ!"
      ],
      "metadata": {
        "id": "V_-RoH_osOzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "dcWHFoJ9byzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ—Å–ª–µ –±–∞–∑–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Å –ø—Ä–æ—Å—Ç—ã–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (TotalQuantity, NumLines, MeanPrice) –∏ ¬´–≥–æ–ª—ã–º¬ª KNN –∏–º–µ–µ—Ç —Å–º—ã—Å–ª –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –∑–∞ —Å—á—ë—Ç –±–æ–ª–µ–µ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è —á–µ–∫–∞ –∏ –±–æ–ª–µ–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–≥–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞.\n",
        "\n",
        "–î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç regression_data.csv, –≤ –∫–æ—Ç–æ—Ä–æ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–µ–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω—ã:\n",
        "\n",
        "–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ—Ä–∑–∏–Ω—ã:\n",
        "\n",
        "TotalQuantity, NumLines, NumUniqueItems, MeanPrice;\n",
        "\n",
        "–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\n",
        "\n",
        "InvoiceHour, InvoiceDayOfWeek, InvoiceMonth;\n",
        "\n",
        "—Ñ–ª–∞–≥ IsNewCustomer, –æ—Ç—Ä–∞–∂–∞—é—â–∏–π, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å –Ω–æ–≤—ã–º;\n",
        "\n",
        "–Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ñ–æ—Ä–º–∞—Ç–∞ qty_<‚Ä¶> –¥–ª—è top-N –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è –≤ —á–µ–∫–∞—Ö —Ç–æ–≤–∞—Ä–æ–≤, –≥–¥–µ –∫–∞–∂–¥—ã–π —Å—Ç–æ–ª–±–µ—Ü –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —Å–∫–æ–ª—å–∫–æ –µ–¥–∏–Ω–∏—Ü –¥–∞–Ω–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –≤–æ—à–ª–æ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —á–µ–∫.\n",
        "\n",
        "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –±–∞–∑–æ–≤–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞, –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:\n",
        "\n",
        "—á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é StandardScaler, —á—Ç–æ–±—ã –ø—Ä–∏–≤–µ—Å—Ç–∏ –∏—Ö –∫ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ–º—É –º–∞—Å—à—Ç–∞–±—É (–¥–ª—è KNN —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ, —Ç–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è—Ö);\n",
        "\n",
        "–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ Country –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é One-Hot Encoding (OneHotEncoder), —á—Ç–æ–±—ã –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—Ä–∞–Ω–µ —Ç–∞–∫–∂–µ –º–æ–≥–ª–∞ —É—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –≤ –º–µ—Ç—Ä–∏–∫–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è;\n",
        "\n",
        "–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (Invoice, CustomerID, InvoiceDate) –≤ –æ–±—É—á–µ–Ω–∏–µ –Ω–µ –≤–∫–ª—é—á–∞—é—Ç—Å—è –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏."
      ],
      "metadata": {
        "id": "sSZmPwMrif_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/–£—á–µ–±–∞/–§—Ä–µ–∏ÃÜ–º–≤–æ—Ä–∫–∏/data\")\n",
        "REG_PATH = DATA_DIR / \"regression_data_hard.csv\"\n",
        "\n",
        "\n",
        "reg_imp = pd.read_csv(REG_PATH, parse_dates=[\"InvoiceDate\"])\n",
        "\n",
        "print(\"Improved regression dataset shape:\", reg_imp.shape)\n",
        "print(reg_imp.head())\n",
        "\n",
        "\n",
        "exclude_cols = [\"TotalCheck\", \"Invoice\", \"CustomerID\", \"InvoiceDate\"]\n",
        "feature_cols = [c for c in reg_imp.columns if c not in exclude_cols]\n",
        "\n",
        "X = reg_imp[feature_cols]\n",
        "y = reg_imp[\"TotalCheck\"].values\n",
        "\n",
        "print(\"\\nFeature columns:\", len(feature_cols))\n",
        "print(\"Example feature columns:\", feature_cols[:10])\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "\n",
        "#    - country: OneHotEncoder\n",
        "numeric_features = [c for c in feature_cols if c != \"Country\"]\n",
        "categorical_features = [\"Country\"]\n",
        "\n",
        "\n",
        "#    - numeric features: StandardScaler\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_features),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "knn_improved = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", KNeighborsRegressor(\n",
        "            n_neighbors=5,\n",
        "            weights=\"uniform\",\n",
        "            metric=\"minkowski\",\n",
        "            p=2,\n",
        "        )),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "knn_improved.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = knn_improved.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Improved KNN regression (extended features + scaling + OHE Country) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tg20wWjihGg",
        "outputId": "37d3fa8a-5c1e-4cbe-f369-2e7d590d3973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved regression dataset shape: (39574, 113)\n",
            "   Invoice  CustomerID         Country         InvoiceDate  TotalCheck  \\\n",
            "0   491725     12346.0  United Kingdom 2009-12-14 08:34:00        45.0   \n",
            "1   491742     12346.0  United Kingdom 2009-12-14 11:00:00        22.5   \n",
            "2   491744     12346.0  United Kingdom 2009-12-14 11:02:00        22.5   \n",
            "3   492718     12346.0  United Kingdom 2009-12-18 10:47:00        22.5   \n",
            "4   492722     12346.0  United Kingdom 2009-12-18 10:55:00         1.0   \n",
            "\n",
            "   TotalQuantity  NumLines  NumUniqueItems  MeanPrice  InvoiceHour  ...  \\\n",
            "0             10         1               1        4.5            8  ...   \n",
            "1              5         1               1        4.5           11  ...   \n",
            "2              5         1               1        4.5           11  ...   \n",
            "3              5         1               1        4.5           10  ...   \n",
            "4              1         1               1        1.0           10  ...   \n",
            "\n",
            "   qty_ANTIQUE_SILVER_TEA_GLASS_ETCHED  qty_HANGING_HEART_ZINC_T_LIGHT_HOLDER  \\\n",
            "0                                  0.0                                    0.0   \n",
            "1                                  0.0                                    0.0   \n",
            "2                                  0.0                                    0.0   \n",
            "3                                  0.0                                    0.0   \n",
            "4                                  0.0                                    0.0   \n",
            "\n",
            "   qty_HANGING_HEART_JAR_T_LIGHT_HOLDER  qty_60_TEATIME_FAIRY_CAKE_CASES  \\\n",
            "0                                   0.0                              0.0   \n",
            "1                                   0.0                              0.0   \n",
            "2                                   0.0                              0.0   \n",
            "3                                   0.0                              0.0   \n",
            "4                                   0.0                              0.0   \n",
            "\n",
            "   qty_72_SWEETHEART_FAIRY_CAKE_CASES  qty_JUMBO_BAG_RED_RETROSPOT  \\\n",
            "0                                 0.0                          0.0   \n",
            "1                                 0.0                          0.0   \n",
            "2                                 0.0                          0.0   \n",
            "3                                 0.0                          0.0   \n",
            "4                                 0.0                          0.0   \n",
            "\n",
            "   qty_JUMBO_BAG_BAROQUE_BLACK_WHITE  qty_JUMBO_BAG_STRAWBERRY  \\\n",
            "0                                0.0                       0.0   \n",
            "1                                0.0                       0.0   \n",
            "2                                0.0                       0.0   \n",
            "3                                0.0                       0.0   \n",
            "4                                0.0                       0.0   \n",
            "\n",
            "   qty_WHITE_HANGING_HEART_T_LIGHT_HOLDER  qty_HAND_OVER_THE_CHOCOLATE_SIGN  \n",
            "0                                     0.0                               0.0  \n",
            "1                                     0.0                               0.0  \n",
            "2                                     0.0                               0.0  \n",
            "3                                     0.0                               0.0  \n",
            "4                                     0.0                               0.0  \n",
            "\n",
            "[5 rows x 113 columns]\n",
            "\n",
            "Feature columns: 109\n",
            "Example feature columns: ['Country', 'TotalQuantity', 'NumLines', 'NumUniqueItems', 'MeanPrice', 'InvoiceHour', 'InvoiceDayOfWeek', 'InvoiceMonth', 'IsNewCustomer', 'qty_DOORMAT_RED_RETROSPOT']\n",
            "Feature matrix shape: (39574, 109)\n",
            "Target vector shape: (39574,)\n",
            "\n",
            "Train size: 31659\n",
            "Test size: 7915\n",
            "\n",
            "=== Improved KNN regression (extended features + scaling + OHE Country) ===\n",
            "MAE:  245.18\n",
            "RMSE: 1005.49\n",
            "R¬≤:   0.3826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–î–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ –º–æ–¥–µ–ª—å KNN —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ one-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å—Ç—Ä–∞–Ω—ã. –ù–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫:\n",
        "\n",
        "MAE ‚âà 245.18\n",
        "\n",
        "RMSE ‚âà 1005.49\n",
        "\n",
        "ùëÖ\n",
        "2\n",
        "‚âà\n",
        "0.38\n",
        "R\n",
        "2\n",
        "‚âà0.38\n",
        "\n",
        "–ü–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –±–∞–∑–æ–≤—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º (MAE ‚âà 154.29, RMSE ‚âà 521.70,\n",
        "ùëÖ\n",
        "2\n",
        "‚âà\n",
        "0.73\n",
        "R\n",
        "2\n",
        "‚âà0.73) –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –∑–∞–º–µ—Ç–Ω–æ —É—Ö—É–¥—à–∏–ª–æ—Å—å: —Å—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –≤–æ–∑—Ä–æ—Å–ª–∞, –∞ –¥–æ–ª—è –æ–±—ä—è—Å–Ω—ë–Ω–Ω–æ–π –≤–∞—Ä–∏–∞—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —Å–Ω–∏–∑–∏–ª–∞—Å—å. –≠—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –¥–ª—è –º–µ—Ç–æ–¥–∞ KNN –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤ —Ç–æ–º —á–∏—Å–ª–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö: one-hot –ø–æ —Å—Ç—Ä–∞–Ω–∞–º –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è top-N —Ç–æ–≤–∞—Ä–æ–≤) –±–µ–∑ –æ—Ç–±–æ—Ä–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–∏–≤–æ–¥–∏—Ç —Å–∫–æ—Ä–µ–µ –∫ ¬´—Ä–∞–∑–º—ã–≤–∞–Ω–∏—é¬ª –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –∏ —É—Å–∏–ª–µ–Ω–∏—é —à—É–º–∞, —á–µ–º –∫ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞.\n",
        "\n",
        "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –≥–∏–ø–æ—Ç–µ–∑–∞ –æ —Ç–æ–º, —á—Ç–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –Ω–∞–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ª—É—á—à–∏—Ç –∫–∞—á–µ—Å—Ç–≤–æ KNN-–º–æ–¥–µ–ª–∏, –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è. –ü—Ä–∏ —ç—Ç–æ–º —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —É–ª—É—á—à–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –æ—Å—Ç–∞—ë—Ç—Å—è –ø–æ–ª–µ–∑–Ω—ã–º: –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–¥–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π, —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å, –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ –∏ —Ç.–ø.) –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –º–æ–≥—É—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –≤—ã–∏–≥—Ä—ã—à –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–æ—Å—Ç—ã–º –±–µ–π–∑–ª–∞–π–Ω–æ–º."
      ],
      "metadata": {
        "id": "5Bi4ZBMLknRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ–ø—Ä–æ–±—É–µ–º —É–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã \"qty_*\" –∏ —É–±—Ä–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã"
      ],
      "metadata": {
        "id": "Z11n7WTmlZPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "# ===== 1. Trim outliers in target =====\n",
        "# Use 99.5 percentile as upper cutoff for TotalCheck\n",
        "q_high = reg_imp[target_col].quantile(0.995)\n",
        "mask = reg_imp[target_col] <= q_high\n",
        "reg_trim = reg_imp[mask].reset_index(drop=True)\n",
        "\n",
        "print(\"Original rows:\", len(reg_imp))\n",
        "print(\"Trimmed rows:\", len(reg_trim))\n",
        "print(\"Cutoff (99.5% quantile) TotalCheck:\", q_high)\n",
        "\n",
        "# ===== 2. Define features on trimmed data (no qty_*) =====\n",
        "qty_cols = [c for c in reg_trim.columns if c.startswith(\"qty_\")]\n",
        "exclude_cols = [\"Invoice\", \"CustomerID\", \"InvoiceDate\", target_col] + qty_cols\n",
        "\n",
        "feature_cols = [c for c in reg_trim.columns if c not in exclude_cols]\n",
        "\n",
        "print(\"\\nFeature columns used for KNN (reduced, trimmed):\", len(feature_cols))\n",
        "print(\"Example feature columns:\", feature_cols[:10])\n",
        "\n",
        "X = reg_trim[feature_cols]\n",
        "y = reg_trim[target_col].values\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "# ===== 3. Train / test split =====\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "# ===== 4. Preprocessing: numeric + Country (OHE) =====\n",
        "numeric_features = [c for c in feature_cols if c != \"Country\"]\n",
        "categorical_features = [\"Country\"] if \"Country\" in feature_cols else []\n",
        "\n",
        "transformers = []\n",
        "if numeric_features:\n",
        "    transformers.append((\"num\", StandardScaler(), numeric_features))\n",
        "if categorical_features:\n",
        "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=transformers)\n",
        "\n",
        "# ===== 5. KNN model =====\n",
        "knn_reduced_trimmed = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", KNeighborsRegressor(\n",
        "            n_neighbors=5,\n",
        "            weights=\"uniform\",\n",
        "            metric=\"minkowski\",\n",
        "            p=2,\n",
        "        )),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ===== 6. Train =====\n",
        "knn_reduced_trimmed.fit(X_train, y_train)\n",
        "\n",
        "# ===== 7. Predict & metrics =====\n",
        "y_pred = knn_reduced_trimmed.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== KNN regression (reduced features + outlier-trimmed target, no qty_*) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apzsPijtqqkC",
        "outputId": "586dcd61-1dbe-4363-d5c5-cc41935bbbf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 39574\n",
            "Trimmed rows: 39376\n",
            "Cutoff (99.5% quantile) TotalCheck: 5739.156000000027\n",
            "\n",
            "Feature columns used for KNN (reduced, trimmed): 9\n",
            "Example feature columns: ['Country', 'TotalQuantity', 'NumLines', 'NumUniqueItems', 'MeanPrice', 'InvoiceHour', 'InvoiceDayOfWeek', 'InvoiceMonth', 'IsNewCustomer']\n",
            "X shape: (39376, 9)\n",
            "y shape: (39376,)\n",
            "\n",
            "Train size: 31500\n",
            "Test size: 7876\n",
            "\n",
            "=== KNN regression (reduced features + outlier-trimmed target, no qty_*) ===\n",
            "MAE:  143.39\n",
            "RMSE: 285.05\n",
            "R¬≤:   0.7382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø–µ—Ä–≤—ã–º –∑–∞–ø—É—Å–∫–æ–º ¬´–ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π¬ª –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏ –≤—ã–±—Ä–æ—Å–æ–≤ –∫–∞—á–µ—Å—Ç–≤–æ –∑–∞–º–µ—Ç–Ω–æ —É–ª—É—á—à–∏–ª–æ—Å—å: —Å—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ —Å–Ω–∏–∑–∏–ª–∞—Å—å, —Ä–∞–∑–±—Ä–æ—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å–æ–∫—Ä–∞—Ç–∏–ª—Å—è, –∞ –¥–æ–ª—è –æ–±—ä—è—Å–Ω—ë–Ω–Ω–æ–π –≤–∞—Ä–∏–∞—Ü–∏–∏ —Ç–∞—Ä–≥–µ—Ç–∞ –≤—ã—Ä–æ—Å–ª–∞ –¥–æ —É—Ä–æ–≤–Ω—è –æ–∫–æ–ª–æ 0.74. –¢–æ –µ—Å—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –±–æ–ª—å—à–∏—Ö —á–µ–∫–æ–≤ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –¥–µ–ª–∞–µ—Ç –º–æ–¥–µ–ª—å –±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤–æ–π –∏ –ª—É—á—à–µ –æ–ø–∏—Å—ã–≤–∞—é—â–µ–π ¬´—Ç–∏–ø–∏—á–Ω–æ–µ¬ª –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π.\n",
        "\n",
        "–ü—Ä–∏ —ç—Ç–æ–º –¥–∞–∂–µ –ø–æ—Å–ª–µ —Ç—Ä–∏–º–º–∏–Ω–≥–∞ –º–æ–¥–µ–ª—å –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ—Å—Ç–∞—ë—Ç—Å—è –Ω–µ–º–Ω–æ–≥–æ —Ö—É–∂–µ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É, —á–µ–º –±–∞–∑–æ–≤–∞—è KNN-–º–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–æ—Å—Ç—ã—Ö –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∏—á: –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Å–æ —Å–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º R¬≤ –æ—Å—Ç–∞—ë—Ç—Å—è –≤—ã—à–µ (‚âà 0.77), –∞ MAE –Ω–∏–∂–µ. –≠—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Å–∞–º–∞ –ø–æ —Å–µ–±–µ —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –≤—ã–∏–≥—Ä—ã—à–∞ –¥–ª—è KNN.\n",
        "\n",
        "–î–∞–ª–µ–µ –ª–æ–≥–∏—á–Ω–æ –ø–µ—Ä–µ–π—Ç–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É —É–ª—É—á—à–µ–Ω–∏—è: –ø–æ–¥–±–æ—Ä—É –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ KNN (—á–∏—Å–ª–æ —Å–æ—Å–µ–¥–µ–π, —Å—Ö–µ–º–∞ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è, –≤—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è) –Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —É–¥–∞—Å—Ç—Å—è –ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—Å–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."
      ],
      "metadata": {
        "id": "bNv4elR3tWwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "# ===== 1. Trim outliers in target =====\n",
        "# Use 99.5 percentile as upper cutoff for TotalCheck\n",
        "q_high = reg_imp[target_col].quantile(0.995)\n",
        "mask = reg_imp[target_col] <= q_high\n",
        "reg_trim = reg_imp[mask].reset_index(drop=True)\n",
        "\n",
        "print(\"Original rows:\", len(reg_imp))\n",
        "print(\"Trimmed rows:\", len(reg_trim))\n",
        "print(\"Cutoff (99.5% quantile) TotalCheck:\", q_high)\n",
        "\n",
        "# ===== 2. Define features on trimmed data (no qty_*) =====\n",
        "qty_cols = [c for c in reg_trim.columns if c.startswith(\"qty_\")]\n",
        "exclude_cols = [\"Invoice\", \"CustomerID\", \"InvoiceDate\", target_col] + qty_cols\n",
        "\n",
        "feature_cols = [c for c in reg_trim.columns if c not in exclude_cols]\n",
        "\n",
        "print(\"\\nFeature columns used for KNN (reduced, trimmed):\", len(feature_cols))\n",
        "print(\"Example feature columns:\", feature_cols[:10])\n",
        "\n",
        "X = reg_trim[feature_cols]\n",
        "y = reg_trim[target_col].values\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "# ===== 3. Train / test split =====\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "# ===== 4. Preprocessing: numeric + Country (OHE) =====\n",
        "numeric_features = [c for c in feature_cols if c != \"Country\"]\n",
        "categorical_features = [\"Country\"] if \"Country\" in feature_cols else []\n",
        "\n",
        "transformers = []\n",
        "if numeric_features:\n",
        "    transformers.append((\"num\", StandardScaler(), numeric_features))\n",
        "if categorical_features:\n",
        "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=transformers)\n",
        "\n",
        "# ===== 5. Pipeline with KNN (for GridSearch) =====\n",
        "base_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", KNeighborsRegressor()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ===== 6. Hyperparameter grid =====\n",
        "param_grid = {\n",
        "    \"model__n_neighbors\": [3, 5, 10, 20, 30],\n",
        "    \"model__weights\": [\"uniform\", \"distance\"],\n",
        "    \"model__p\": [1, 2],  # 1 = Manhattan, 2 = Euclidean\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=base_pipeline,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "print(\"\\nRunning GridSearchCV...\")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Best CV MAE:\", -grid.best_score_)\n",
        "\n",
        "# ===== 7. Evaluate best model on test set =====\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Tuned KNN regression (reduced features + outlier-trimmed target, no qty_*) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty3HrvQBtZLp",
        "outputId": "1c958dfc-da1e-49b8-9b52-b3f63a297ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 39574\n",
            "Trimmed rows: 39376\n",
            "Cutoff (99.5% quantile) TotalCheck: 5739.156000000027\n",
            "\n",
            "Feature columns used for KNN (reduced, trimmed): 9\n",
            "Example feature columns: ['Country', 'TotalQuantity', 'NumLines', 'NumUniqueItems', 'MeanPrice', 'InvoiceHour', 'InvoiceDayOfWeek', 'InvoiceMonth', 'IsNewCustomer']\n",
            "X shape: (39376, 9)\n",
            "y shape: (39376,)\n",
            "\n",
            "Train size: 31500\n",
            "Test size: 7876\n",
            "\n",
            "Running GridSearchCV...\n",
            "Best params: {'model__n_neighbors': 10, 'model__p': 1, 'model__weights': 'distance'}\n",
            "Best CV MAE: 137.2060344450502\n",
            "\n",
            "=== Tuned KNN regression (reduced features + outlier-trimmed target, no qty_*) ===\n",
            "MAE:  134.57\n",
            "RMSE: 271.46\n",
            "R¬≤:   0.7626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (k, –º–µ—Ç—Ä–∏–∫–∞, —Å—Ö–µ–º–∞ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è) –Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–æ–∑–≤–æ–ª–∏–ª —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ KNN –Ω–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–º –∏ —É—Å–µ—á—ë–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ: MAE –∏ RMSE —Å–Ω–∏–∑–∏–ª–∏—Å—å, –∞ R¬≤ –≤—ã—Ä–æ—Å —Å ~0.74 –¥–æ ~0.76. –û–¥–Ω–∞–∫–æ –¥–∞–∂–µ –ø–æ—Å–ª–µ —Ç—é–Ω–∏–Ω–≥–∞ –¥–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –¥–∞—ë—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤—ã–∏–≥—Ä—ã—à–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª—å—é KNN –Ω–∞ —Ç—Ä—ë—Ö –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö, –ø—Ä–∏ —Ç–æ–º —á—Ç–æ –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —è–≤–ª—è–µ—Ç—Å—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ –∑–∞—Ç—Ä–∞—Ç–Ω–æ–π (–ø–æ—Ä—è–¥–∫–∞ 10 –º–∏–Ω—É—Ç –Ω–∞ –æ–¥–∏–Ω –ø—Ä–æ–≥–æ–Ω). –£—á–∏—Ç—ã–≤–∞—è —ç—Ç–æ, –ø—Ä–æ—Å—Ç–æ–π KNN —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ—Å—Ç–∞—ë—Ç—Å—è —Ä–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º –±–µ–π–∑–ª–∞–π–Ω–æ–º –¥–ª—è –¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏."
      ],
      "metadata": {
        "id": "3XVVYRbXwU6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–ò–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞"
      ],
      "metadata": {
        "id": "g7mPwjZxwZPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "F-6ozqaInqi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ KNN –Ω–∞ ¬´–æ–±—ã—á–Ω—ã—Ö¬ª –¥–∞–Ω–Ω—ã—Ö, —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –±–µ–π–∑–ª–∞–π–Ω–∞: –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∞–≥—Ä–µ–≥–∞—Ç—ã –ø–æ —á–µ–∫—É (TotalQuantity, NumLines, MeanPrice), –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π ‚Äí TotalCheck. –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –±–µ–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–±—Ä–æ—Å–æ–≤, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–ø—Ä—è–º—É—é —Å—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞—Å—Ç–æ–º–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –±–∞–∑–æ–≤–æ–π –±–∏–±–ª–∏–æ—Ç–µ—á–Ω–æ–π –º–æ–¥–µ–ª—å—é."
      ],
      "metadata": {
        "id": "FMhy53galTAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "class MyKNNRegressor:\n",
        "    def __init__(self, n_neighbors=5, p=2, weights=\"uniform\"):\n",
        "\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.p = p\n",
        "        self.weights = weights\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "\n",
        "        if X.ndim != 2:\n",
        "            raise ValueError(\"X must be 2D array of shape (n_samples, n_features)\")\n",
        "        if y.ndim != 1:\n",
        "            raise ValueError(\"y must be 1D array of shape (n_samples,)\")\n",
        "\n",
        "        if X.shape[0] != y.shape[0]:\n",
        "            raise ValueError(\"X and y must have the same number of samples\")\n",
        "\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "        return self\n",
        "\n",
        "    def _minkowski_distance(self, x):\n",
        "\n",
        "        diff = self.X_train - x\n",
        "\n",
        "        if self.p == 1:\n",
        "            dist = np.sum(np.abs(diff), axis=1)\n",
        "        elif self.p == 2:\n",
        "            dist = np.sqrt(np.sum(diff ** 2, axis=1))\n",
        "        else:\n",
        "            dist = np.sum(np.abs(diff) ** self.p, axis=1) ** (1.0 / self.p)\n",
        "\n",
        "        return dist\n",
        "\n",
        "    def _predict_one(self, x):\n",
        "\n",
        "        distances = self._minkowski_distance(x)\n",
        "\n",
        "        k = min(self.n_neighbors, len(distances))\n",
        "        neighbor_idx = np.argpartition(distances, k - 1)[:k]\n",
        "\n",
        "        neighbor_y = self.y_train[neighbor_idx]\n",
        "        neighbor_dist = distances[neighbor_idx]\n",
        "\n",
        "        if self.weights == \"uniform\":\n",
        "            return neighbor_y.mean()\n",
        "        elif self.weights == \"distance\":\n",
        "            eps = 1e-8\n",
        "            w = 1.0 / (neighbor_dist + eps)\n",
        "            return np.sum(w * neighbor_y) / np.sum(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown weights type: {self.weights}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        if self.X_train is None or self.y_train is None:\n",
        "            raise RuntimeError(\"You must call fit() before predict().\")\n",
        "\n",
        "        X = np.asarray(X)\n",
        "        if X.ndim == 1:\n",
        "            X = X.reshape(1, -1)\n",
        "\n",
        "        preds = []\n",
        "        for i in range(X.shape[0]):\n",
        "            y_hat = self._predict_one(X[i])\n",
        "            preds.append(y_hat)\n",
        "        return np.array(preds)\n",
        "\n",
        "\n",
        "feature_cols = [\"TotalQuantity\", \"NumLines\", \"MeanPrice\"]\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "X = reg_simple[feature_cols].values\n",
        "y = reg_simple[target_col].values\n",
        "\n",
        "print(\"\\nFeature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "my_knn = MyKNNRegressor(\n",
        "    n_neighbors=5,\n",
        "    p=2,\n",
        "    weights=\"uniform\",\n",
        ")\n",
        "\n",
        "my_knn.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = my_knn.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Custom KNN regression (simple features, no scaling) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR6al2lKweAV",
        "outputId": "284a9a42-99e0-45ae-d304-433c75280ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature matrix shape: (39574, 3)\n",
            "Target vector shape: (39574,)\n",
            "\n",
            "Train size: 31659\n",
            "Test size: 7915\n",
            "\n",
            "=== Custom KNN regression (simple features, no scaling) ===\n",
            "MAE:  154.29\n",
            "RMSE: 521.70\n",
            "R¬≤:   0.7252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–î–ª—è –∫–∞—Å—Ç–æ–º–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ KNN –±–µ–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è MAE ‚âà 154.29, RMSE ‚âà 521.70 –∏\n",
        "ùëÖ\n",
        "2\n",
        "‚âà\n",
        "0.73\n",
        "R\n",
        "2\n",
        "‚âà0.73, —á—Ç–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±–∏–±–ª–∏–æ—Ç–µ—á–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ KNeighborsRegressor —Å —Ç–µ–º–∏ –∂–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏. –≠—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞."
      ],
      "metadata": {
        "id": "3yRVIC2izMvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "fyDX0IEwnusg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–î–∞–ª–µ–µ —Ä–µ–∞–ª–∏–∑–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –±—ç–π–∑–ª–∞–π–Ω–∞"
      ],
      "metadata": {
        "id": "FuaqckfnnuLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "class MyKNNRegressor:\n",
        "    def __init__(self, n_neighbors=5, p=2, weights=\"uniform\"):\n",
        "\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.p = p\n",
        "        self.weights = weights\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "\n",
        "        if X.ndim != 2:\n",
        "            raise ValueError(\"X must be 2D array of shape (n_samples, n_features)\")\n",
        "        if y.ndim != 1:\n",
        "            raise ValueError(\"y must be 1D array of shape (n_samples,)\")\n",
        "\n",
        "        if X.shape[0] != y.shape[0]:\n",
        "            raise ValueError(\"X and y must have the same number of samples\")\n",
        "\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "        return self\n",
        "\n",
        "    def _minkowski_distance(self, x):\n",
        "\n",
        "        diff = self.X_train - x\n",
        "\n",
        "        if self.p == 1:\n",
        "            dist = np.sum(np.abs(diff), axis=1)\n",
        "        elif self.p == 2:\n",
        "            dist = np.sqrt(np.sum(diff ** 2, axis=1))\n",
        "        else:\n",
        "            dist = np.sum(np.abs(diff) ** self.p, axis=1) ** (1.0 / self.p)\n",
        "\n",
        "        return dist\n",
        "\n",
        "    def _predict_one(self, x):\n",
        "\n",
        "        distances = self._minkowski_distance(x)\n",
        "\n",
        "        k = min(self.n_neighbors, len(distances))\n",
        "        neighbor_idx = np.argpartition(distances, k - 1)[:k]\n",
        "\n",
        "        neighbor_y = self.y_train[neighbor_idx]\n",
        "        neighbor_dist = distances[neighbor_idx]\n",
        "\n",
        "        if self.weights == \"uniform\":\n",
        "            return neighbor_y.mean()\n",
        "        elif self.weights == \"distance\":\n",
        "            eps = 1e-8\n",
        "            w = 1.0 / (neighbor_dist + eps)\n",
        "            return np.sum(w * neighbor_y) / np.sum(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown weights type: {self.weights}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        if self.X_train is None or self.y_train is None:\n",
        "            raise RuntimeError(\"You must call fit() before predict().\")\n",
        "\n",
        "        X = np.asarray(X)\n",
        "        if X.ndim == 1:\n",
        "            X = X.reshape(1, -1)\n",
        "\n",
        "        preds = []\n",
        "        for i in range(X.shape[0]):\n",
        "            y_hat = self._predict_one(X[i])\n",
        "            preds.append(y_hat)\n",
        "        return np.array(preds)\n",
        "\n",
        "\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/–£—á–µ–±–∞/–§—Ä–µ–∏ÃÜ–º–≤–æ—Ä–∫–∏/data\")\n",
        "SIMPLE_REG_PATH = DATA_DIR / \"regression_data_simple.csv\"\n",
        "\n",
        "reg_simple = pd.read_csv(SIMPLE_REG_PATH)\n",
        "\n",
        "print(\"Simple regression dataset shape:\", reg_simple.shape)\n",
        "print(reg_simple.head())\n",
        "\n",
        "feature_cols = [\"TotalQuantity\", \"NumLines\", \"MeanPrice\"]\n",
        "target_col = \"TotalCheck\"\n",
        "\n",
        "q_high = reg_simple[target_col].quantile(0.995)\n",
        "mask = reg_simple[target_col] <= q_high\n",
        "reg_trim = reg_simple[mask].reset_index(drop=True)\n",
        "\n",
        "print(\"\\nOriginal rows:\", len(reg_simple))\n",
        "print(\"Trimmed rows:\", len(reg_trim))\n",
        "print(\"Cutoff (99.5% quantile) TotalCheck:\", q_high)\n",
        "\n",
        "X = reg_trim[feature_cols].values\n",
        "y = reg_trim[target_col].values\n",
        "\n",
        "print(\"\\nFeature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "my_knn = MyKNNRegressor(\n",
        "    n_neighbors=5,\n",
        "    p=2,\n",
        "    weights=\"uniform\",\n",
        ")\n",
        "\n",
        "my_knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = my_knn.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Custom KNN regression (simple features, trimmed target + scaling) ===\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤:   {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gijJrGLvzNAr",
        "outputId": "1cae6a8a-6c13-4edd-fa33-9b3855d2e425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple regression dataset shape: (39574, 6)\n",
            "   Invoice  CustomerID  TotalCheck  TotalQuantity  NumLines  MeanPrice\n",
            "0   489434     13085.0      505.30            166         8   4.081250\n",
            "1   489435     13085.0      145.80             60         4   2.625000\n",
            "2   489436     13078.0      630.33            193        19   3.730526\n",
            "3   489437     15362.0      310.75            145        23   3.628261\n",
            "4   489438     18102.0     2286.24            826        17   2.591176\n",
            "\n",
            "Original rows: 39574\n",
            "Trimmed rows: 39376\n",
            "Cutoff (99.5% quantile) TotalCheck: 5739.156000000027\n",
            "\n",
            "Feature matrix shape: (39376, 3)\n",
            "Target vector shape: (39376,)\n",
            "\n",
            "Train size: 31500\n",
            "Test size: 7876\n",
            "\n",
            "=== Custom KNN regression (simple features, trimmed target + scaling) ===\n",
            "MAE:  96.50\n",
            "RMSE: 227.01\n",
            "R¬≤:   0.8472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–î–ª—è –∫–∞—Å—Ç–æ–º–Ω–æ–π KNN-–º–æ–¥–µ–ª–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –±–µ–π–∑–ª–∞–π–Ω–æ–º (—É—Å–µ—á—ë–Ω–Ω—ã–π –ø–æ –≤–µ—Ä—Ö–Ω–µ–º—É –∫–≤–∞–Ω—Ç–∏–ª—é —Ç–∞—Ä–≥–µ—Ç TotalCheck + –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤) –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è MAE ‚âà 96.50, RMSE ‚âà 227.01 –∏\n",
        "ùëÖ\n",
        "2\n",
        "‚âà\n",
        "0.85\n",
        "R\n",
        "2\n",
        "‚âà0.85, —á—Ç–æ —Ç–∞–∫–∂–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±–∏–±–ª–∏–æ—Ç–µ—á–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö. –≠—Ç–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∏ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω–æ–≥–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞."
      ],
      "metadata": {
        "id": "9tSXIgnZ0VFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è"
      ],
      "metadata": {
        "id": "ToGqcEm3li11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "crO13V5cmrq6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGLjY6aAmrq8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "fd1ewdMnmrq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##–ò–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞"
      ],
      "metadata": {
        "id": "6_le72cGmrq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "FS7yNUJOmrq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "7IitQ7_Nmrq_"
      }
    }
  ]
}